{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fine-Tuning-Albert-for-QA.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "mount_file_id": "1swAwM2ml_u7rdO4molmOoXvssLMBSSaH",
      "authorship_tag": "ABX9TyNwFcDRwVg7f0/xSGuo3Huc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "dae4509ff1c8410a83eed3e953518569": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2e817ce21562452393d69658772c0f43",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_2b5a44c5209647499f8a6c6dbe4451d4",
              "IPY_MODEL_c7475ce0a57d4acdbc94b691b13edbd9",
              "IPY_MODEL_df3cd23b6a8548ddac1b2732fda88e21"
            ]
          }
        },
        "2e817ce21562452393d69658772c0f43": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2b5a44c5209647499f8a6c6dbe4451d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_312fde3281654ab9b6dbe8e17b972423",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2f92c2163f9940cda905f15f5f7d2208"
          }
        },
        "c7475ce0a57d4acdbc94b691b13edbd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_daed4b4248304fd8a27f3fddc3a52adf",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 760289,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 760289,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6c5b2f9268bb4adba9ccfc39816b65fc"
          }
        },
        "df3cd23b6a8548ddac1b2732fda88e21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c05d29ca19c24231a42479bd593f344b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 742k/742k [00:00&lt;00:00, 5.58MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_95e5dd12f96b42cdb61e90741ad39695"
          }
        },
        "312fde3281654ab9b6dbe8e17b972423": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2f92c2163f9940cda905f15f5f7d2208": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "daed4b4248304fd8a27f3fddc3a52adf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6c5b2f9268bb4adba9ccfc39816b65fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c05d29ca19c24231a42479bd593f344b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "95e5dd12f96b42cdb61e90741ad39695": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bfe512600c364de29d4defdc7ab0191c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d506d0934a324038901ceb315a3a6046",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_8a161d838978446d96f1ea6f1a120ade",
              "IPY_MODEL_50dd95472fc84d3cb7af73c3d3afa190",
              "IPY_MODEL_2f01bccb39174a598135298d8db342e4"
            ]
          }
        },
        "d506d0934a324038901ceb315a3a6046": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8a161d838978446d96f1ea6f1a120ade": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_40cc57e434fe4cbebfb494cc40850265",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1ed4b807bf5a4dea800e93cf1010ee1e"
          }
        },
        "50dd95472fc84d3cb7af73c3d3afa190": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_83b8c44defcd49b284179318221ebc15",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1312669,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1312669,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3eb84b2ae9894560a579f17132afa0b1"
          }
        },
        "2f01bccb39174a598135298d8db342e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2358ac09eb334e4d917bcd932611ca76",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.25M/1.25M [00:00&lt;00:00, 6.52MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ea3b16fe39194e56a9c10b38d394208a"
          }
        },
        "40cc57e434fe4cbebfb494cc40850265": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1ed4b807bf5a4dea800e93cf1010ee1e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "83b8c44defcd49b284179318221ebc15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3eb84b2ae9894560a579f17132afa0b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2358ac09eb334e4d917bcd932611ca76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ea3b16fe39194e56a9c10b38d394208a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f75b81412f084e58a56b82e96c9e6451": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_336fb5d877934c8b94483e517ac163a6",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_0cc68080c2a043569dbf536b26bd5d33",
              "IPY_MODEL_7fbfcdba2de9487d8287b910af3f3d60",
              "IPY_MODEL_5560a048ef794375a83d746d1b50fe10"
            ]
          }
        },
        "336fb5d877934c8b94483e517ac163a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0cc68080c2a043569dbf536b26bd5d33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_363f5ad72de545a186b8272ac241b4d3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_75ee6dfccefc494c8d4617239ba848cc"
          }
        },
        "7fbfcdba2de9487d8287b910af3f3d60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ecfc2d75503c4b4387b63e9e79d65e90",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 684,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 684,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e896550c9ee04fdaaf22da25de58e8e2"
          }
        },
        "5560a048ef794375a83d746d1b50fe10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_36efb94a6e514f01a3dfadaa4ebe08a6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 684/684 [00:00&lt;00:00, 27.9kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4e7375915b7242bca8a482a392f38a1b"
          }
        },
        "363f5ad72de545a186b8272ac241b4d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "75ee6dfccefc494c8d4617239ba848cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ecfc2d75503c4b4387b63e9e79d65e90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e896550c9ee04fdaaf22da25de58e8e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "36efb94a6e514f01a3dfadaa4ebe08a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4e7375915b7242bca8a482a392f38a1b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d8b594a229a14309a4b840319cca6b79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_db49481bbb2a404fa008caefa460e624",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_8f99023b659d4d1a89b6fab264cc4714",
              "IPY_MODEL_b95fe4d1be6f4b1e8102e2ba100933aa",
              "IPY_MODEL_4f8dd98d5dcf40b3beb4ea7ccad78f4b"
            ]
          }
        },
        "db49481bbb2a404fa008caefa460e624": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8f99023b659d4d1a89b6fab264cc4714": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e8e14dbb56944d458928cd8085e47c04",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f61ce5b8a74b4f05bcbd09ebf7a5a288"
          }
        },
        "b95fe4d1be6f4b1e8102e2ba100933aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_6be6cbc8e1074d449a892f216916aaec",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 47376696,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 47376696,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d6a05001d61e4dc8884f79dd7f61df35"
          }
        },
        "4f8dd98d5dcf40b3beb4ea7ccad78f4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ba5eb770c1ca4701836fa1366e603019",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 45.2M/45.2M [00:00&lt;00:00, 54.8MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a8925fd7da3845368b75a99462dbac53"
          }
        },
        "e8e14dbb56944d458928cd8085e47c04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f61ce5b8a74b4f05bcbd09ebf7a5a288": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6be6cbc8e1074d449a892f216916aaec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d6a05001d61e4dc8884f79dd7f61df35": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ba5eb770c1ca4701836fa1366e603019": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a8925fd7da3845368b75a99462dbac53": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Crystal-Reshea/FinBert-Albert-nlp/blob/main/Fine_Tuning_Albert_for_QA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Overview\n",
        "Actions Completed\n",
        "* Trained Albert base model for Question Answering\n",
        "     * Basis for code: https://towardsdatascience.com/how-to-fine-tune-a-q-a-transformer-86f91ec92997\n",
        "     * Trained on 3 epochs, batch size = 8 \n",
        "     * Ideally I would like to train on 4 epochs, with a batch size of 16 and learning rate of 3e-5. I didn't do this the first time out of caution of RAM but I should have enough\n",
        "* Prepped 10-K data\n",
        "  * The 10-K data is large and there are many lines that we do not need. I extracted text by groups of lines and then removed new lines. \n",
        "  * Most bert models including Albert have a max sequence of 512 so there should be a method of how to handle this. Currently the tokenizer truncates the text if it hits the max. There's another idea below. \n",
        "* Used model on Item 7\n",
        "  * The model does okay. It got one question wrong but it may be due to the text being truncated. (We could truncate the text and use the question on all parts of the text and then accept the answer with the highest score.) \n",
        "\n",
        "Things I'd like to do: \n",
        "* Validate model and evaluate performance\n",
        "* organize Item 7 by sections (headings)\n",
        "* Retrain for better results"
      ],
      "metadata": {
        "id": "GbxsnXYZytw_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install transformers"
      ],
      "metadata": {
        "id": "Wbmorc7k4FlG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3UewQx1x6RfV",
        "outputId": "dc8d0803-640f-4273-c5bc-c1f5957e71a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "def read_squad(path):\n",
        "    # open JSON file and load intro dictionary\n",
        "    with open(path, 'rb') as file:\n",
        "        squad2_dict = json.load(file)\n",
        "        \n",
        "    contexts = []\n",
        "    questions = []\n",
        "    answers = []\n",
        "    # iterate through all data in squad data\n",
        "    for group in squad2_dict['data']:\n",
        "        for passage in group['paragraphs']:\n",
        "            context = passage['context']\n",
        "            for qa in passage['qas']:\n",
        "                question = qa['question']\n",
        "                # check if we need to be extracting from 'answers' or 'plausible_answers'\n",
        "                if 'plausible_answers' in qa.keys():\n",
        "                    access = 'plausible_answers'\n",
        "                else:\n",
        "                    access = 'answers'\n",
        "                for answer in qa[access]:\n",
        "                    # append data to lists\n",
        "                    contexts.append(context)\n",
        "                    questions.append(question)\n",
        "                    answers.append(answer)\n",
        "    # return formatted data lists\n",
        "    return contexts, questions, answers\n",
        "\n",
        "# execute our read SQuAD function for training and validation sets\n",
        "train_contexts, train_questions, train_answers = read_squad('/content/drive/MyDrive/NLP_POC/train-v2.0.json')\n",
        "val_contexts, val_questions, val_answers = read_squad('/content/drive/MyDrive/NLP_POC/dev-v2.0.json')"
      ],
      "metadata": {
        "id": "I8OZT2LU2QPS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_questions[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K3KnJgYx2lGj",
        "outputId": "5e5d32f5-6613-48a7-b3ba-91e8653c4ace"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['When did Beyonce start becoming popular?',\n",
              " 'What areas did Beyonce compete in when she was growing up?',\n",
              " \"When did Beyonce leave Destiny's Child and become a solo singer?\",\n",
              " 'In what city and state did Beyonce  grow up? ',\n",
              " 'In which decade did Beyonce become famous?']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def add_end_idx(answers, contexts):\n",
        "    # loop through each answer-context pair\n",
        "    for answer, context in zip(answers, contexts):\n",
        "        # gold_text refers to the answer we are expecting to find in context\n",
        "        gold_text = answer['text']\n",
        "        # we already know the start index\n",
        "        start_idx = answer['answer_start']\n",
        "        # and ideally this would be the end index...\n",
        "        end_idx = start_idx + len(gold_text)\n",
        "\n",
        "        # ...however, sometimes squad answers are off by a character or two\n",
        "        if context[start_idx:end_idx] == gold_text:\n",
        "            # if the answer is not off :)\n",
        "            answer['answer_end'] = end_idx\n",
        "        else:\n",
        "            # this means the answer is off by 1-2 tokens\n",
        "            for n in [1, 2]:\n",
        "                if context[start_idx-n:end_idx-n] == gold_text:\n",
        "                    answer['answer_start'] = start_idx - n\n",
        "                    answer['answer_end'] = end_idx - n\n",
        "            \n",
        "# and apply the function to our two answer lists\n",
        "add_end_idx(train_answers, train_contexts)\n",
        "add_end_idx(val_answers, val_contexts)"
      ],
      "metadata": {
        "id": "YxCiW6Rk24Pr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AlbertTokenizerFast\n",
        "# initialize the tokenizer\n",
        "tokenizer = AlbertTokenizerFast.from_pretrained('albert-base-v2')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112,
          "referenced_widgets": [
            "dae4509ff1c8410a83eed3e953518569",
            "2e817ce21562452393d69658772c0f43",
            "2b5a44c5209647499f8a6c6dbe4451d4",
            "c7475ce0a57d4acdbc94b691b13edbd9",
            "df3cd23b6a8548ddac1b2732fda88e21",
            "312fde3281654ab9b6dbe8e17b972423",
            "2f92c2163f9940cda905f15f5f7d2208",
            "daed4b4248304fd8a27f3fddc3a52adf",
            "6c5b2f9268bb4adba9ccfc39816b65fc",
            "c05d29ca19c24231a42479bd593f344b",
            "95e5dd12f96b42cdb61e90741ad39695",
            "bfe512600c364de29d4defdc7ab0191c",
            "d506d0934a324038901ceb315a3a6046",
            "8a161d838978446d96f1ea6f1a120ade",
            "50dd95472fc84d3cb7af73c3d3afa190",
            "2f01bccb39174a598135298d8db342e4",
            "40cc57e434fe4cbebfb494cc40850265",
            "1ed4b807bf5a4dea800e93cf1010ee1e",
            "83b8c44defcd49b284179318221ebc15",
            "3eb84b2ae9894560a579f17132afa0b1",
            "2358ac09eb334e4d917bcd932611ca76",
            "ea3b16fe39194e56a9c10b38d394208a",
            "f75b81412f084e58a56b82e96c9e6451",
            "336fb5d877934c8b94483e517ac163a6",
            "0cc68080c2a043569dbf536b26bd5d33",
            "7fbfcdba2de9487d8287b910af3f3d60",
            "5560a048ef794375a83d746d1b50fe10",
            "363f5ad72de545a186b8272ac241b4d3",
            "75ee6dfccefc494c8d4617239ba848cc",
            "ecfc2d75503c4b4387b63e9e79d65e90",
            "e896550c9ee04fdaaf22da25de58e8e2",
            "36efb94a6e514f01a3dfadaa4ebe08a6",
            "4e7375915b7242bca8a482a392f38a1b"
          ]
        },
        "id": "4AWG0Qqd2_lu",
        "outputId": "a5e24917-47a1-4411-c1cd-304038e9be82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dae4509ff1c8410a83eed3e953518569",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/742k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bfe512600c364de29d4defdc7ab0191c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.25M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f75b81412f084e58a56b82e96c9e6451",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/684 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenize\n",
        "train_encodings = tokenizer(train_contexts, train_questions, truncation=True, padding=True)\n",
        "val_encodings = tokenizer(val_contexts, val_questions, truncation=True, padding=True)"
      ],
      "metadata": {
        "id": "Cxjv2MX74DYg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.decode(train_encodings['input_ids'][250])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "_y2tqraw40z7",
        "outputId": "f309dbe8-9923-412f-ad90-60e5dafd6d19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'[CLS] her fourth studio album 4 was released on june 28, 2011 in the us. 4 sold 310,000 copies in its first week and debuted atop the billboard 200 chart, giving beyonce her fourth consecutive number-one album in the us. the album was preceded by two of its singles \"run the world (girls)\" and \"best thing i never had\", which both attained moderate success. the fourth single \"love on top\" was a commercial success in the us. 4 also produced four other singles; \"party\", \"countdown\", \"i care\" and \"end of time\". \"eat, play, love\", a cover story written by beyonce for essence that detailed her 2010 career break, won her a writing award from the new york association of black journalists. in late 2011, she took the stage at new york\\'s roseland ballroom for four nights of special performances: the 4 intimate nights with beyonce concerts saw the performance of her 4 album to a standing room only.[SEP] where did beyonce perform for four nights of standing room only concerts in 2011?[SEP]<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>'"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def add_token_positions(encodings, answers):\n",
        "    # initialize lists to contain the token indices of answer start/end\n",
        "    start_positions = []\n",
        "    end_positions = []\n",
        "    for i in range(len(answers)):\n",
        "        # append start/end token position using char_to_token method\n",
        "        start_positions.append(encodings.char_to_token(i, answers[i]['answer_start']))\n",
        "        end_positions.append(encodings.char_to_token(i, answers[i]['answer_end']))\n",
        "\n",
        "        # if start position is None, the answer passage has been truncated\n",
        "        if start_positions[-1] is None:\n",
        "            start_positions[-1] = tokenizer.model_max_length\n",
        "        # end position cannot be found, char_to_token found space, so shift position until found\n",
        "        shift = 1\n",
        "        while end_positions[-1] is None:\n",
        "            end_positions[-1] = encodings.char_to_token(i, answers[i]['answer_end'] - shift)\n",
        "            shift += 1\n",
        "    # update our encodings object with the new token-based start/end positions\n",
        "    encodings.update({'start_positions': start_positions, 'end_positions': end_positions})\n",
        "\n",
        "# apply function to our data\n",
        "add_token_positions(train_encodings, train_answers)\n",
        "add_token_positions(val_encodings, val_answers)"
      ],
      "metadata": {
        "id": "KCpa1pJN5SUD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_encodings.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ANRGF_YB5Vmi",
        "outputId": "7ade76bc-0154-4fb3-e527-34fa32e50243"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'start_positions', 'end_positions'])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AlbertTokenizer, AlbertForQuestionAnswering\n",
        "model = AlbertForQuestionAnswering.from_pretrained('albert-base-v2')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156,
          "referenced_widgets": [
            "d8b594a229a14309a4b840319cca6b79",
            "db49481bbb2a404fa008caefa460e624",
            "8f99023b659d4d1a89b6fab264cc4714",
            "b95fe4d1be6f4b1e8102e2ba100933aa",
            "4f8dd98d5dcf40b3beb4ea7ccad78f4b",
            "e8e14dbb56944d458928cd8085e47c04",
            "f61ce5b8a74b4f05bcbd09ebf7a5a288",
            "6be6cbc8e1074d449a892f216916aaec",
            "d6a05001d61e4dc8884f79dd7f61df35",
            "ba5eb770c1ca4701836fa1366e603019",
            "a8925fd7da3845368b75a99462dbac53"
          ]
        },
        "id": "ddv5GqKW8eQs",
        "outputId": "c48da7dd-3cd2-4b02-aeb6-a0335fa22880"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d8b594a229a14309a4b840319cca6b79",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/45.2M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at albert-base-v2 were not used when initializing AlbertForQuestionAnswering: ['predictions.decoder.bias', 'predictions.dense.weight', 'predictions.LayerNorm.bias', 'predictions.LayerNorm.weight', 'predictions.bias', 'predictions.decoder.weight', 'predictions.dense.bias']\n",
            "- This IS expected if you are initializing AlbertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing AlbertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of AlbertForQuestionAnswering were not initialized from the model checkpoint at albert-base-v2 and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "class SquadDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings):\n",
        "        self.encodings = encodings\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encodings.input_ids)\n",
        "\n",
        "# build datasets for both our training and validation sets\n",
        "train_dataset = SquadDataset(train_encodings)\n",
        "val_dataset = SquadDataset(val_encodings)"
      ],
      "metadata": {
        "id": "z0SIARRY6Db8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from transformers import AdamW\n",
        "from tqdm import tqdm\n",
        "\n",
        "# setup GPU/CPU\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "# move model over to detected device\n",
        "model.to(device)\n",
        "# activate training mode of model\n",
        "model.train()\n",
        "# initialize adam optimizer with weight decay (reduces chance of overfitting)\n",
        "optim = AdamW(model.parameters(), lr=5e-5)\n",
        "\n",
        "# initialize data loader for training data\n",
        "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
        "\n",
        "for epoch in range(3):\n",
        "    # set model to train mode\n",
        "    model.train()\n",
        "    # setup loop (we use tqdm for the progress bar)\n",
        "    loop = tqdm(train_loader, leave=True)\n",
        "    for batch in loop:\n",
        "        # initialize calculated gradients (from prev step)\n",
        "        optim.zero_grad()\n",
        "        # pull all the tensor batches required for training\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        start_positions = batch['start_positions'].to(device)\n",
        "        end_positions = batch['end_positions'].to(device)\n",
        "        # train model on batch and return outputs (incl. loss)\n",
        "        outputs = model(input_ids, attention_mask=attention_mask,\n",
        "                        start_positions=start_positions,\n",
        "                        end_positions=end_positions)\n",
        "        # extract loss\n",
        "        loss = outputs[0]\n",
        "        # calculate loss for every parameter that needs grad update\n",
        "        loss.backward()\n",
        "        # update parameters\n",
        "        optim.step()\n",
        "        # print relevant info to progress bar\n",
        "        loop.set_description(f'Epoch {epoch}')\n",
        "        loop.set_postfix(loss=loss.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2N38lcNC6Gy6",
        "outputId": "fe0b679f-0057-4503-b381-a20fad42e708"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0: 100%|██████████| 16290/16290 [2:06:57<00:00,  2.14it/s, loss=0.796]\n",
            "Epoch 1: 100%|██████████| 16290/16290 [2:06:56<00:00,  2.14it/s, loss=1.16]\n",
            "Epoch 2: 100%|██████████| 16290/16290 [2:06:56<00:00,  2.14it/s, loss=0.769]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = '/content/drive/MyDrive/NLP_POC/models'\n",
        "model.save_pretrained(model_path)\n",
        "tokenizer.save_pretrained(model_path)"
      ],
      "metadata": {
        "id": "OFjGtZ7nDpx6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac6b4c2a-624b-41de-bb91-4e180c36ed46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('/content/drive/MyDrive/NLP_POC/models/tokenizer_config.json',\n",
              " '/content/drive/MyDrive/NLP_POC/models/special_tokens_map.json',\n",
              " '/content/drive/MyDrive/NLP_POC/models/tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Started at 3:21 pm <br>\n",
        "Check-in #1 at 3:45 pm <br>\n",
        "Check-in #2 at 4:02 pm | epoch 0, 33% <br>\n",
        "Check-in #3 at 4:27 pn | epoch 0, 52% <br>\n",
        "Check-in #4 at 4:58 pm | epoch 0, 77% <br> \n",
        "Check-in #5 at 5:08 pm | epoch 0, 84% <br>\n",
        "Check-in #6 at 5:40 pm | epoch 1, 9%  <br> \n",
        "Check-in #7 at 6:03 pm | epoch 1, 28% <br> \n",
        "Check-in #8 at 6:23 pm | epoch 1, 43% <br> \n",
        "Check-in #9 at 6:38 pm | epoch 1, 56% <br> \n",
        "Check-in #10 at 7:00 pm | epoch 1, 73% <br>\n",
        "Check-in #11 at 7:13 pm | epoch1, 83% <br>\n",
        "Check-in #12 at 7:50 pm | epoch 2, 12% <br> \n",
        "Check-in #13 at 8:36 pm | epoch 2, 48% <br> \n",
        "Check-in #14 at 8:55 pm | epoch 2, 63% <br>\n",
        "Check-in #15 at 9:21 pm | epoch 2, 83% <br>\n",
        "Check-in #16 at 9:43 pm | epoch 2, 100%"
      ],
      "metadata": {
        "id": "P6js5OuHsZES"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = AlbertForQuestionAnswering.from_pretrained(model_path)\n",
        "tokenizer = AlbertTokenizerFast.from_pretrained(model_path)"
      ],
      "metadata": {
        "id": "cAGNGgsv-H09"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training Code to try Later for Better Performance"
      ],
      "metadata": {
        "id": "3CAgFyEBk5Ci"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# If time allows try training on these parameters\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import AdamW\n",
        "from tqdm import tqdm\n",
        "\n",
        "# setup GPU/CPU\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "# move model over to detected device\n",
        "model.to(device)\n",
        "# activate training mode of model\n",
        "model.train()\n",
        "# initialize adam optimizer with weight decay (reduces chance of overfitting)\n",
        "optim = AdamW(model.parameters(), lr=3e-5)\n",
        "\n",
        "# initialize data loader for training data\n",
        "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
        "\n",
        "for epoch in range(4):\n",
        "    # set model to train mode\n",
        "    model.train()\n",
        "    # setup loop (we use tqdm for the progress bar)\n",
        "    loop = tqdm(train_loader, leave=True)\n",
        "    for batch in loop:\n",
        "        # initialize calculated gradients (from prev step)\n",
        "        optim.zero_grad()\n",
        "        # pull all the tensor batches required for training\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        start_positions = batch['start_positions'].to(device)\n",
        "        end_positions = batch['end_positions'].to(device)\n",
        "        # train model on batch and return outputs (incl. loss)\n",
        "        outputs = model(input_ids, attention_mask=attention_mask,\n",
        "                        start_positions=start_positions,\n",
        "                        end_positions=end_positions)\n",
        "        # extract loss\n",
        "        loss = outputs[0]\n",
        "        # calculate loss for every parameter that needs grad update\n",
        "        loss.backward()\n",
        "        # update parameters\n",
        "        optim.step()\n",
        "        # print relevant info to progress bar\n",
        "        loop.set_description(f'Epoch {epoch}')\n",
        "        loop.set_postfix(loss=loss.item())"
      ],
      "metadata": {
        "id": "ZVTWZLmO-vtB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using the New Model\n"
      ],
      "metadata": {
        "id": "QKEEWpxAhq98"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-KH3DEI-hvZC",
        "outputId": "7f41725c-7389-44a6-bc45-8f15428055e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.14.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.46)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.2.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.2)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "hySlK_fOjYiy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers\n",
        "from transformers import AlbertForQuestionAnswering\n",
        "from transformers import AlbertTokenizerFast"
      ],
      "metadata": {
        "id": "FH7GOPeIhy_S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = AlbertForQuestionAnswering.from_pretrained('/content/drive/MyDrive/NLP_POC/models')"
      ],
      "metadata": {
        "id": "zNKv8pQTh2Ad"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AlbertTokenizerFast.from_pretrained('/content/drive/MyDrive/NLP_POC/models')"
      ],
      "metadata": {
        "id": "uJ0lMQ2BiULC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Function to Process Answers through Model"
      ],
      "metadata": {
        "id": "5pu7ad4Lkc7n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def answer_question(question, answer_text):\n",
        "    '''\n",
        "    Takes a `question` string and an `answer_text` string (which contains the\n",
        "    answer), and identifies the words within the `answer_text` that are the\n",
        "    answer. Prints them out.\n",
        "    '''\n",
        "    # ======== Tokenize ========\n",
        "    # Apply the tokenizer to the input text, treating them as a text-pair.\n",
        "    input_ids = tokenizer.encode(question, answer_text, truncation=True,)\n",
        "\n",
        "    # Report how long the input sequence is.\n",
        "    print('Query has {:,} tokens.\\n'.format(len(input_ids)))\n",
        "\n",
        "    # ======== Set Segment IDs ========\n",
        "    # Search the input_ids for the first instance of the `[SEP]` token.\n",
        "    sep_index = input_ids.index(tokenizer.sep_token_id)\n",
        "\n",
        "    # The number of segment A tokens includes the [SEP] token istelf.\n",
        "    num_seg_a = sep_index + 1\n",
        "\n",
        "    # The remainder are segment B.\n",
        "    num_seg_b = len(input_ids) - num_seg_a\n",
        "\n",
        "    # Construct the list of 0s and 1s.\n",
        "    segment_ids = [0]*num_seg_a + [1]*num_seg_b\n",
        "\n",
        "    # There should be a segment_id for every input token.\n",
        "    assert len(segment_ids) == len(input_ids)\n",
        "\n",
        "    # ======== Evaluate ========\n",
        "    # Run our example through the model.\n",
        "    outputs = model(torch.tensor([input_ids]), # The tokens representing our input text.\n",
        "                    token_type_ids=torch.tensor([segment_ids]), # The segment IDs to differentiate question from answer_text\n",
        "                    return_dict=True) \n",
        "\n",
        "    start_scores = outputs.start_logits\n",
        "    end_scores = outputs.end_logits\n",
        "\n",
        "    # ======== Reconstruct Answer ========\n",
        "    # Find the tokens with the highest `start` and `end` scores.\n",
        "    answer_start = torch.argmax(start_scores)\n",
        "    answer_end = torch.argmax(end_scores)\n",
        "\n",
        "    # Get the string versions of the input tokens.\n",
        "    tokens = tokenizer.convert_ids_to_tokens(input_ids)\n",
        "\n",
        "    # Start with the first token.\n",
        "    answer = tokens[answer_start]\n",
        "\n",
        "    # Select the remaining answer tokens and join them with whitespace.\n",
        "    for i in range(answer_start + 1, answer_end + 1):\n",
        "        \n",
        "        # If it's a subword token, then recombine it with the previous token.\n",
        "        if tokens[i][0:2] == '##':\n",
        "            answer += tokens[i][2:]\n",
        "        \n",
        "        # Otherwise, add a space then the token.\n",
        "        else:\n",
        "            answer += ' ' + tokens[i]\n",
        "\n",
        "    return answer"
      ],
      "metadata": {
        "id": "qP5k29hXivJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Simple Sample Questions"
      ],
      "metadata": {
        "id": "dAzq1GxdkuU9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "answer_question(\"What is the best restaurant in the United States?\", \"The most beloved restaurant in the united states is called Cook Out. Cook out is a national treasure everyone loves it.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TYXgCsb5izHj",
        "outputId": "fa57bef4-b7f3-4ec1-be37-ac0aec8706c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query has 36 tokens.\n",
            "\n",
            "Answer: \"▁cook ▁out .\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"What country did Tik Tok start in?\"\n",
        "context = \"TikTok, known in China as Douyin (Chinese: 抖音; pinyin: Dǒuyīn), is a video-focused social networking service owned by Chinese company ByteDance.[4] It hosts a variety of short-form user videos, from genres like pranks, stunts, tricks, jokes, dance, and entertainment[5][6] with durations from 15 seconds to three minutes.[7][8][9] TikTok is an international version of Douyin, which was originally released in the Chinese market in September 2016.[10] TikTok was launched in 2017 for iOS and Android in most markets outside of mainland China; however, it became available worldwide only after merging with another Chinese social media service, Musical.ly, on 2 August 2018. TikTok and Douyin have almost the same user interface but no access to each other's content. Their servers are each based in the market where the respective app is available.[11] The two products are similar, but features are not identical. Douyin includes an in-video search feature that can search by people's faces for more videos of them and other features such as buying, booking hotels and making geo-tagged reviews.[12] Since its launch in 2016, TikTok/Douyin rapidly gained popularity in East Asia, South Asia, Southeast Asia, the United States, Turkey, Russia, and other parts of the world.[13][14] As of October 2020, TikTok surpassed over 2 billion mobile downloads worldwide.[15][16][17] Morning Consult ranked TikTok as the third fastest growing brand of 2020, after only Zoom and Peacock.[18]\""
      ],
      "metadata": {
        "id": "g_Osy_2ejgki"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "answer_question(question, context)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8S0OTsb2kRIn",
        "outputId": "3c74970e-7a75-42a0-e410-b5b9d0646db6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query has 376 tokens.\n",
            "\n",
            "Answer: \"▁china\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"About how many people are using Tik Tok?\"\n",
        "answer_question(question, context)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NPEPF35MliMi",
        "outputId": "7e3a54b7-5494-41d2-b27e-26feae517902"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query has 377 tokens.\n",
            "\n",
            "Answer: \"▁2 ▁billion\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# A future goal is to fix the preprocessing of the data so that it is trained to return no answer if not possible.\n",
        "question = \"What country did Instagram start in?\"\n",
        "answer_question(question, context)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_EBvT0OglAfj",
        "outputId": "14b40bca-6373-43ed-9bdf-d0f55976f166"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query has 373 tokens.\n",
            "\n",
            "Answer: \"▁china\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Processing the 10-k Form - Item 7"
      ],
      "metadata": {
        "id": "Z48rjuJRlxzJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file = '/content/drive/MyDrive/NLP_POC/bby-202110k.txt'"
      ],
      "metadata": {
        "id": "Q1q3DmuqsEQP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract1(txt, start, end):\n",
        "  assert start <= end, \"Start should be less than or equal to end\"\n",
        "  lines = []\n",
        "  i = 1\n",
        "  flag = False\n",
        "  with open(txt, 'r') as file: \n",
        "    for line in file:\n",
        "        if end == i: \n",
        "          lines.append(line)\n",
        "          break\n",
        "        elif flag == True:\n",
        "          lines.append(line)\n",
        "        if start == i:\n",
        "          flag = True\n",
        "          lines.append(line)\n",
        "        i+=1\n",
        "  file.close()\n",
        "  return ''.join(lines)"
      ],
      "metadata": {
        "id": "6Pwk8KNXqw8X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start=[1135,1156,1161,1168,1172,1189,1209,1235,1292,1297,1307,1311,1318,1322,1326,1340,1352,1365,1592,1610,1626,1646,1659,1673,1677,1682,1687,1692,1697,1719,1723,1737,1748,1753,1757,1761,1766,1770,1778,1783,1785,1788,1831,1837,1867,1877,1964,1971,1985,1991,1994,2002,2048,2099,2115]\n",
        "end = [1154,1158,1164,1168,1182,1207,1229,1284,1293,1298,1307,1314,1318,1322,1336,1350,1359,1408,1604,1624,1644,1652,1670,1673,1678,1683,1688,1694,1712,1721,1735,1745,1749,1753,1757,1762,1766,1770,1780,1783,1786,1825,1835,1865,1871,1888,1967,1977,1988,1992,1995,2042,2093,2113,2142]"
      ],
      "metadata": {
        "id": "gaV_7ZuPrdMv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "paragraph = []\n",
        "for i in range(len(start)): \n",
        "  paragraph.append(extract1(file, start[i],end[i]))\n",
        "\n",
        "joined_paragraph = ''.join(paragraph)\n",
        "print(joined_paragraph)"
      ],
      "metadata": {
        "id": "5sK6tooCrrky"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "joined_paragraph = joined_paragraph.replace('\\n', ' ')"
      ],
      "metadata": {
        "id": "irV9R-MfrpSf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Proposed Idea for better results\n",
        "* Break up Item 7 into section based off of the headings. And then Ask questions for those headings. \n",
        "* Think about a way to chunck the large sections"
      ],
      "metadata": {
        "id": "q7hURADnvS_y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def answer_question(question, answer_text):\n",
        "    '''\n",
        "    Takes a `question` string and an `answer_text` string (which contains the\n",
        "    answer), and identifies the words within the `answer_text` that are the\n",
        "    answer. Prints them out.\n",
        "    '''\n",
        "    # ======== Tokenize ========\n",
        "    # Apply the tokenizer to the input text, treating them as a text-pair.\n",
        "    input_ids = tokenizer.encode(question, answer_text, truncation=True,)\n",
        "\n",
        "    # Report how long the input sequence is.\n",
        "    # print('Query has {:,} tokens.\\n'.format(len(input_ids)))\n",
        "\n",
        "    # ======== Set Segment IDs ========\n",
        "    # Search the input_ids for the first instance of the `[SEP]` token.\n",
        "    sep_index = input_ids.index(tokenizer.sep_token_id)\n",
        "\n",
        "    # The number of segment A tokens includes the [SEP] token istelf.\n",
        "    num_seg_a = sep_index + 1\n",
        "\n",
        "    # The remainder are segment B.\n",
        "    num_seg_b = len(input_ids) - num_seg_a\n",
        "\n",
        "    # Construct the list of 0s and 1s.\n",
        "    segment_ids = [0]*num_seg_a + [1]*num_seg_b\n",
        "\n",
        "    # There should be a segment_id for every input token.\n",
        "    assert len(segment_ids) == len(input_ids)\n",
        "\n",
        "    # ======== Evaluate ========\n",
        "    # Run our example through the model.\n",
        "    outputs = model(torch.tensor([input_ids]), # The tokens representing our input text.\n",
        "                    token_type_ids=torch.tensor([segment_ids]), # The segment IDs to differentiate question from answer_text\n",
        "                    return_dict=True) \n",
        "\n",
        "    start_scores = outputs.start_logits\n",
        "    end_scores = outputs.end_logits\n",
        "\n",
        "    # ======== Reconstruct Answer ========\n",
        "    # Find the tokens with the highest `start` and `end` scores.\n",
        "    answer_start = torch.argmax(start_scores)\n",
        "    answer_end = torch.argmax(end_scores)\n",
        "\n",
        "    # Get the string versions of the input tokens.\n",
        "    tokens = tokenizer.convert_ids_to_tokens(input_ids)\n",
        "    \n",
        "    alpha = {'a':'a', 'b':'b', 'c':'c', 'd':'d', 'e':'e', 'f':'f', 'g':'g','h':'h','i':'i', 'j':'j', 'k':'k', 'l':'l',\n",
        "             'm':'m', 'n':'n', 'o':'o', 'p':'p', 'q':'q', 'r':'r', 's':'s', 't':'t', 'u':'u', 'v':'v', 'w':'w', 'x':'x', 'y':'y', 'z':'z',\n",
        "             '.':'.', '!':'!', ',':',', '(':'('}\n",
        "    # Start with the first token.\n",
        "    if tokens[answer_start][0:1] not in alpha:\n",
        "      answer = tokens[answer_start][1:]\n",
        "    else: \n",
        "      answer = tokens[answer_start]\n",
        "\n",
        "    # Select the remaining answer tokens and join them with whitespace.\n",
        "    for i in range(answer_start + 1, answer_end + 1):\n",
        "        \n",
        "        # If it's a subword token, then recombine it with the previous token.\n",
        "        if tokens[i][0:1] not in alpha :\n",
        "            answer += \" \" + tokens[i][1:]\n",
        "        \n",
        "        # Otherwise, add a space then the token.\n",
        "        else:\n",
        "            answer += '' + tokens[i]\n",
        "    return answer"
      ],
      "metadata": {
        "id": "3BVeos42BWeP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "context = joined_paragraph\n",
        "questions = ['What type of company is this?', 'What changes have been made in response to Covid-19?',\n",
        "             'How many stores will have closed by the end of the fiscal year 2021?', ]"
      ],
      "metadata": {
        "id": "gJpXnswdurUj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "overview = context[:2707]"
      ],
      "metadata": {
        "id": "KtmDw5x47y5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "answer_to_fix = answer_question(questions[0], overview)\n",
        "print(answer_to_fix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zfIn9qswE8R4",
        "outputId": "7f813d59-9fa5-49c5-dd6d-49be6b91d105"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "omnichannel retailer that makes it easy for our customers to feel at home. we sell a wide assortment of merchandise in the home, baby, beauty & wellness markets and operate under the names bed bath & beyond   bbb  , buybuy baby   baby  , and harmon, harmon face values, or face values  collectively,  harmon  . we also operate decorist, an online interior design platform that provides personalized home design services. in addition, we are a partner in a joint venture, which operates retail stores\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "answer_to_fix"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "u6_3OS0rHuQ7",
        "outputId": "01662c64-47af-42a6-87de-92d6b161801c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'▁we have undertaken significant changes over the past year  including extensive changes to executive leadership '"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x[0][500:]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "20JOCAmRFOxA",
        "outputId": "0ee36e0b-e4a7-429f-f1a7-e523e7ba190d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-5.2800, -3.4725, -2.4860, -5.0513, -0.2213, -5.1217, -3.9617, -4.2264,\n",
              "         2.3934,  1.9139, -4.7331, -1.5098], grad_fn=<SliceBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(questions)):\n",
        "  print(\"Question: \" + questions[i] + \"\\nAnswer: \" + answer_question(questions[i], overview))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pOYp4gTI8r9-",
        "outputId": "447b35ab-fc09-4e70-a76c-01eaad0391b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What type of company is this?\n",
            "Answer: ▁omnichannel▁retailer▁that▁makes▁it▁easy▁for▁our▁customers▁to▁feel▁at▁home.▁we▁sell▁a▁wide▁assortment▁of▁merchandise▁in▁the▁home,▁baby,▁beauty▁&▁wellness▁markets▁and▁operate▁under▁the▁names▁bed▁bath▁&▁beyond▁(\"bbb\"),▁buybuy▁baby▁(\"baby\"),▁and▁harmon,▁harmon▁face▁values,▁or▁face▁values▁(collectively,▁\"harmon\").▁we▁also▁operate▁decorist,▁an▁online▁interior▁design▁platform▁that▁provides▁personalized▁home▁design▁services.▁in▁addition,▁we▁are▁a▁partner▁in▁a▁joint▁venture,▁which▁operates▁retail▁stores\n",
            "Question: What changes have been made in response to Covid-19?\n",
            "Answer: ▁we▁have▁undertaken▁significant▁changes▁over▁the▁past▁year,▁including▁extensive▁changes▁to▁executive▁leadership,\n",
            "Question: How many stores will have closed by the end of the fiscal year 2021?\n",
            "Answer: ▁one\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokens[1][0:1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "YP19PheUAlf9",
        "outputId": "90c49a93-f165-4cf3-b39f-095cf53e4615"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'▁'"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ======== Tokenize ========\n",
        "    # Apply the tokenizer to the input text, treating them as a text-pair.\n",
        "    input_ids = tokenizer.encode(question, answer_text, truncation=True,)\n",
        "\n",
        "    # Report how long the input sequence is.\n",
        "    # print('Query has {:,} tokens.\\n'.format(len(input_ids)))\n",
        "\n",
        "    # ======== Set Segment IDs ========\n",
        "    # Search the input_ids for the first instance of the `[SEP]` token.\n",
        "    sep_index = input_ids.index(tokenizer.sep_token_id)\n",
        "\n",
        "    # The number of segment A tokens includes the [SEP] token istelf.\n",
        "    num_seg_a = sep_index + 1\n",
        "\n",
        "    # The remainder are segment B.\n",
        "    num_seg_b = len(input_ids) - num_seg_a\n",
        "\n",
        "    # Construct the list of 0s and 1s.\n",
        "    segment_ids = [0]*num_seg_a + [1]*num_seg_b\n"
      ],
      "metadata": {
        "id": "1XkUsU4ZB1Sh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = tokenizer.encode(questions[0], overview, truncation=True,)"
      ],
      "metadata": {
        "id": "3x35Wj9pB2WV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}